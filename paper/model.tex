% !TEX root = template.tex

\section{Processing Pipeline}
\label{sec:processing_architecture}

\begin{figure*}[h]
	\centering
	\includegraphics[width=1\textwidth]{images/processing_pipeline.jpg}
	\caption{Processing pipeline}
\end{figure*}

The task of HAR 'in the wild' is a difficult problem, and many aspects need to be considered when dealing in that situation. As reported in \cite{blunck2013heterogeneity} the three major types of heterogeneties which yield impairments in Human Activity recognition are:
\begin{itemize}
	\item \textbf{Sensor Biases}: To keep the overall cost of a smartphone low, low costs accelerometer and gyroscope sensor are used, yielding a poor-calibrated, inaccurate an of limited granularity and range acquired signals. So, among this type of sensors we could observe differences in precision, resolution, range and also biases. Usually an initial sensors calibration are made by smartphones manufactures, but due to rotation or misalignment of the sensor to the circuit board of the final product, this could introduce errors. Furthermore, if a device experience shock, e.g falling on the ground, the sensor can be misaligned causing unwanted biases.
	\item \textbf{Sampling Rate Heterogeneity}: Often popular smartphones vary in terms of the default and supported sampling frequencies for accelerometer and gyroscope sensor. In the dataset TODO riportare link used for this experiment for example we are dealing with smartphone where the sampling frequency varies from 50Hz to 200Hz.
	\item \textbf{Sampling Rate Instability}: This phenomenon is specific to a single device and regards the regularity of the time span between successive measurements. Different factors could accentuate this problem, including heavy multitasking or high I/O load in the mobile device. Multitasking effect in particular is a major problem: smartphone usually prioritizes among various running tasks and doing so could extremely affects the sensor sampling of and HAR application running on the device. In our collected dataset with a 100 Hz sampling rate, we observe a time span between consecutive measurement of TODO, even if the smartphone was hold in \textit{airplane mode} to reduce at the minimum this effect. The Fig. TODO shows the amount of different time-span present in our dataset.
\end{itemize}

Furthermore, if we considered a real use case scenarios of a HAR mobile app we must also consider that smartphones can be positioned and oriented in different ways. For example a smartphone could lay in trouser pockets (back and front) or maybe inside accessories like in a pouch or in a bag in different orientation. These different initial model settings have huge effects in prediction accuracy of an HAR predictor, especially if the model has been trained on a dataset that consist of activity measurement coming from only one fixed position and orientation of the smartphone, as is usually the case. 

To tackle all these problems we decide to adopt a smart pre-processing pipeline as show in Fig. TODO, consisting of 3 main blocks.

The first block called Linear Interpolator is in charge of mitigate the problems regarding the Sampling Rate Heterogeneity and Sampling Rate Instabilities as discussed previously. It main purpose is to down-sample the input data to a fixed sampling rate in our case 50 samples/second. 

The second block called Orientation Independent Transformation is used to represent data coming form different orientation of the smartphone in a rotation independent space. In this way all the signal are projected in a new space whose orientation is independent of that of the smartphone and aligned with gravity and the direction of motion. In this way an user can place his smartphone in whatever position he or she wants, without any impairment in the performance of the prediction model.

Our last block consists of a data centering operation, applied for centering signals among y-axis that are presented only for the Covolutional Layer and not for the Autoencoder. The reason of this choice would be clear in the section TODO. As reported in \cite{ignatov2018real}, time series centering standardize the input data, making the task for the CNN easier. Data normalization instead must be avoided because does not help in this situation since it significantly distorts time series shape, removing magnitude information which is critical for activities differentiation.

After the preprocessing pipeline we adopt a novel Learning framework. It is composed of CNN augmented with features coming from an autoencoder. As discussed in \cite{ignatov2018real} CNNs learns filters that are applied to small sub-regions of the data, and therefore they are able to capture local data pattern and their variations. Additionally, due to a small number of connections and high parallelism the amount of computations and running time of CNNs is significantly lower compared to other deep learning algorithm. This yield these model perfect for real-time HAR apps, where these models could also run in a restrict environment as one like smartphones where computation resources are limited. The only drawback of CCNs is that they fall behind in capturing global properties of the signal, and as proposed in \cite{ignatov2018real} they eliminate this problem by augmenting CNNs with some basic statistical features that comprise this aspects of the data. But as opposed of what done in this latter work, where they used manual extracted features, we decided to opt for a autoencoder features extractors which can provide more robust feature. For this reason we train an auto-encoder separately on the training data and then use the encoder part to augment the CNN features used for the last classification Feed forward Neural Network. 

\section{Signals and Features}
\label{sec:model}

In questo caso si va nel dettaglio della parte di preprocessing (parte trattegiata nel mio schema come preprocessing)

Parlare del dataset, come sono stati processati i dati (interpolazione lineare), parlare della time-window applicata di 2,5s, e parlare del rotational indipendent trasform per ruorare nuovamente i dati. L'applicazione del centering per la sola rete CNN e l'estrazione delle basic feature per risimulare il lavoro fatto in \cite{ignatov2018real}.

\subsection{Dataset \& Meausurement Setup}
Parlare di come abbiamo splittato il dataset, quindi escludendo gli utenti a e b per fare in modo di testare le performance cambiando compltamente utente.

Introduzione e spiegazione del dataset eterogeneo, preso da: riportare link.

Accenare dell'acquisizione di un nostro dataset alla stessa maniera, a 100 HZ in varie posizioni per testare poi anche tutto il dataset!

\subsection{Signal preprocessing}

\begin{itemize}
	\item interpolazione lineare / downsampling
	\item rotational invariant citare tutti i paper e come funziona
	\item centering
\end{itemize}

\subsection{Feature vector}
\begin{itemize}
	\item window strategy
	\item basic feature extraction
	\item autoencoder feature extraction
\end{itemize}

\section{Learning Framework}
\label{sec:learning_framework}

\begin{figure*}[h]
	\centering
	\includegraphics[width=1\textwidth]{images/full_architecture.jpg}
	\caption{Learning Framework}
\end{figure*}

Desctivere qui invece la parte tratteggiata come learning framework

Descivere prima l'autoencoder, come Ã¨ stato costruito e come viene allenato. TODO luca

Passare alla decrizione della mia archittetura, come sono stai selezionati gli iper-parametri, ecc ecc.

