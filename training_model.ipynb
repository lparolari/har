{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            0         1         2         3         4         5         6    \\\n0     -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n1     -5.056885 -6.000000 -6.000000 -6.000000 -6.000000 -5.172044 -6.000000   \n2     -5.908984 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n3     -6.000000 -6.000000 -5.283560 -5.862354 -6.000000 -6.000000 -5.063055   \n4     -5.982080 -5.695964 -6.000000 -6.000000 -6.000000 -5.510071 -6.000000   \n...         ...       ...       ...       ...       ...       ...       ...   \n22584 -2.313599 -2.000000 -2.000000 -2.000000 -2.000000 -1.000000 -1.000000   \n22585 -1.493705 -1.000000 -1.000000  0.000000  0.000000  0.000000  0.000000   \n22586  0.000000  0.000000  0.000000  0.000000 -1.000000 -1.000000  0.000000   \n22587  0.000000  0.000000  0.000000  0.720006  0.707711 -0.721697 -4.587960   \n22588 -4.646136 -5.000000 -4.175241 -3.000000 -3.000000 -3.000000 -2.171858   \n\n            7         8         9    ...  740  741  742  743  744  745  746  \\\n0     -6.000000 -6.000000 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1     -6.000000 -6.000000 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2     -5.000000 -5.566284 -5.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3     -6.000000 -5.242467 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4     -6.000000 -6.000000 -5.634155  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n22584 -1.000000 -0.306832  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22585  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22586  0.000000  1.000000  0.380511  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22587 -6.000000 -4.724040 -3.346348  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22588 -1.599592 -1.829834 -2.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       747  748  749  \n0      0.0  0.0  0.0  \n1      0.0  0.0  0.0  \n2      0.0  0.0  0.0  \n3      0.0  0.0  0.0  \n4      0.0  0.0  0.0  \n...    ...  ...  ...  \n22584  0.0  0.0  0.0  \n22585  0.0  0.0  0.0  \n22586  0.0  0.0  0.0  \n22587  0.0  0.0  0.0  \n22588  0.0  0.0  0.0  \n\n[22589 rows x 750 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_df = pd.read_csv('./datasets/dataset_50_2.5.csv', header=None)\n",
    "\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      user    device     gt\n0        a  nexus4_1  stand\n1        a  nexus4_1  stand\n2        a  nexus4_1  stand\n3        a  nexus4_1  stand\n4        a  nexus4_1  stand\n...    ...       ...    ...\n22584    i  s3mini_2   walk\n22585    i  s3mini_2   walk\n22586    i  s3mini_2   walk\n22587    i  s3mini_2   walk\n22588    i  s3mini_2   walk\n\n[22589 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv('./datasets/dataset_labels_50_2.5.csv')\n",
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              0         1         2         3         4         5         6  \\\n0     -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n1     -5.056885 -6.000000 -6.000000 -6.000000 -6.000000 -5.172044 -6.000000   \n2     -5.908984 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n3     -6.000000 -6.000000 -5.283560 -5.862354 -6.000000 -6.000000 -5.063055   \n4     -5.982080 -5.695964 -6.000000 -6.000000 -6.000000 -5.510071 -6.000000   \n...         ...       ...       ...       ...       ...       ...       ...   \n22584 -2.313599 -2.000000 -2.000000 -2.000000 -2.000000 -1.000000 -1.000000   \n22585 -1.493705 -1.000000 -1.000000  0.000000  0.000000  0.000000  0.000000   \n22586  0.000000  0.000000  0.000000  0.000000 -1.000000 -1.000000  0.000000   \n22587  0.000000  0.000000  0.000000  0.720006  0.707711 -0.721697 -4.587960   \n22588 -4.646136 -5.000000 -4.175241 -3.000000 -3.000000 -3.000000 -2.171858   \n\n              7         8         9  ...  743  744  745  746  747  748  749  \\\n0     -6.000000 -6.000000 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n1     -6.000000 -6.000000 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2     -5.000000 -5.566284 -5.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3     -6.000000 -5.242467 -6.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4     -6.000000 -6.000000 -5.634155  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n22584 -1.000000 -0.306832  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22585  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22586  0.000000  1.000000  0.380511  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22587 -6.000000 -4.724040 -3.346348  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n22588 -1.599592 -1.829834 -2.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n       user    device     gt  \n0         a  nexus4_1  stand  \n1         a  nexus4_1  stand  \n2         a  nexus4_1  stand  \n3         a  nexus4_1  stand  \n4         a  nexus4_1  stand  \n...     ...       ...    ...  \n22584     i  s3mini_2   walk  \n22585     i  s3mini_2   walk  \n22586     i  s3mini_2   walk  \n22587     i  s3mini_2   walk  \n22588     i  s3mini_2   walk  \n\n[22589 rows x 753 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.concat([data_df,label_df], axis=1)\n",
    "print(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              0         1         2         3         4         5         6  \\\n0     -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n1     -5.056885 -6.000000 -6.000000 -6.000000 -6.000000 -5.172044 -6.000000   \n2     -5.908984 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000 -6.000000   \n3     -6.000000 -6.000000 -5.283560 -5.862354 -6.000000 -6.000000 -5.063055   \n4     -5.982080 -5.695964 -6.000000 -6.000000 -6.000000 -5.510071 -6.000000   \n...         ...       ...       ...       ...       ...       ...       ...   \n22584 -2.313599 -2.000000 -2.000000 -2.000000 -2.000000 -1.000000 -1.000000   \n22585 -1.493705 -1.000000 -1.000000  0.000000  0.000000  0.000000  0.000000   \n22586  0.000000  0.000000  0.000000  0.000000 -1.000000 -1.000000  0.000000   \n22587  0.000000  0.000000  0.000000  0.720006  0.707711 -0.721697 -4.587960   \n22588 -4.646136 -5.000000 -4.175241 -3.000000 -3.000000 -3.000000 -2.171858   \n\n              7         8         9  ...  748  749  user    device  gt_bike  \\\n0     -6.000000 -6.000000 -6.000000  ...  0.0  0.0     a  nexus4_1        0   \n1     -6.000000 -6.000000 -6.000000  ...  0.0  0.0     a  nexus4_1        0   \n2     -5.000000 -5.566284 -5.000000  ...  0.0  0.0     a  nexus4_1        0   \n3     -6.000000 -5.242467 -6.000000  ...  0.0  0.0     a  nexus4_1        0   \n4     -6.000000 -6.000000 -5.634155  ...  0.0  0.0     a  nexus4_1        0   \n...         ...       ...       ...  ...  ...  ...   ...       ...      ...   \n22584 -1.000000 -0.306832  0.000000  ...  0.0  0.0     i  s3mini_2        0   \n22585  0.000000  0.000000  0.000000  ...  0.0  0.0     i  s3mini_2        0   \n22586  0.000000  1.000000  0.380511  ...  0.0  0.0     i  s3mini_2        0   \n22587 -6.000000 -4.724040 -3.346348  ...  0.0  0.0     i  s3mini_2        0   \n22588 -1.599592 -1.829834 -2.000000  ...  0.0  0.0     i  s3mini_2        0   \n\n       gt_sit  gt_stairsdown  gt_stairsup  gt_stand  gt_walk  \n0           0              0            0         1        0  \n1           0              0            0         1        0  \n2           0              0            0         1        0  \n3           0              0            0         1        0  \n4           0              0            0         1        0  \n...       ...            ...          ...       ...      ...  \n22584       0              0            0         0        1  \n22585       0              0            0         0        1  \n22586       0              0            0         0        1  \n22587       0              0            0         0        1  \n22588       0              0            0         0        1  \n\n[22589 rows x 758 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_one_hot_df = pd.get_dummies(dataset_df, columns=['gt'])\n",
    "print(dataset_one_hot_df)"
   ]
  },
  {
   "source": [
    "## SPLITTING DATASET IN TRAIN AND TEST SET"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN SET\n\tSit:\t\t3694 (20.44%)\n\tStand:\t\t2968 (16.42%)\n\tWalk:\t\t3991 (22.09%)\n\tBike:\t\t2533 (14.02%)\n\tStairs up:\t2735 (15.13%)\n\tStairs down:\t2150 (11.90%)\nVALIDATION SET\n\tSit:\t\t936 (20.72%)\n\tStand:\t\t736 (16.29%)\n\tWalk:\t\t1018 (22.53%)\n\tBike:\t\t623 (13.79%)\n\tStairs up:\t686 (15.18%)\n\tStairs down:\t519 (11.49%)\n"
     ]
    }
   ],
   "source": [
    "# Keep 20% of the data out for validation\n",
    "### START CODE HERE ### (1 line)\n",
    "train_reference_df, val_reference_df = train_test_split(dataset_one_hot_df, test_size=0.2, shuffle=True, random_state=123)\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "def print_dataset_statistics(train_reference_df, val_reference_df):\n",
    "\n",
    "    # Count the elements in the sets\n",
    "    num_train_data_sit = sum(train_reference_df['gt_sit'] == 1)\n",
    "    num_train_data_stand = sum(train_reference_df['gt_stand'] == 1)\n",
    "    num_train_data_walk = sum(train_reference_df['gt_walk'] == 1)\n",
    "    num_train_data_bike = sum(train_reference_df['gt_bike'] == 1)\n",
    "    num_train_data_stairs_up = sum(train_reference_df['gt_stairsup'] == 1)\n",
    "    num_train_data_stairs_down = sum(train_reference_df['gt_stairsdown'] == 1)\n",
    "\n",
    "    num_val_data_sit = sum(val_reference_df['gt_sit'] == 1)\n",
    "    num_val_data_stand = sum(val_reference_df['gt_stand'] == 1)\n",
    "    num_val_data_walk = sum(val_reference_df['gt_walk'] == 1)\n",
    "    num_val_data_bike = sum(val_reference_df['gt_bike'] == 1)\n",
    "    num_val_data_stairs_up = sum(val_reference_df['gt_stairsup'] == 1)\n",
    "    num_val_data_stairs_down = sum(val_reference_df['gt_stairsdown'] == 1)\n",
    "\n",
    "\n",
    "\n",
    "    print('TRAIN SET')\n",
    "    print('\\tSit:\\t\\t{} ({:.2f}%)'.format(num_train_data_sit, 100 * num_train_data_sit / len(train_reference_df)))\n",
    "    print('\\tStand:\\t\\t{} ({:.2f}%)'.format(num_train_data_stand, 100 * num_train_data_stand / len(train_reference_df)))\n",
    "    print('\\tWalk:\\t\\t{} ({:.2f}%)'.format(num_train_data_walk, 100 * num_train_data_walk / len(train_reference_df)))\n",
    "    print('\\tBike:\\t\\t{} ({:.2f}%)'.format(num_train_data_bike, 100 * num_train_data_bike / len(train_reference_df)))\n",
    "    print('\\tStairs up:\\t{} ({:.2f}%)'.format(num_train_data_stairs_up, 100 * num_train_data_stairs_up / len(train_reference_df)))\n",
    "    print('\\tStairs down:\\t{} ({:.2f}%)'.format(num_train_data_stairs_down, 100 * num_train_data_stairs_down / len(train_reference_df)))\n",
    "\n",
    "\n",
    "    print('VALIDATION SET')\n",
    "    print('\\tSit:\\t\\t{} ({:.2f}%)'.format(num_val_data_sit, 100 * num_val_data_sit / len(val_reference_df)))\n",
    "    print('\\tStand:\\t\\t{} ({:.2f}%)'.format(num_val_data_stand, 100 * num_val_data_stand / len(val_reference_df)))\n",
    "    print('\\tWalk:\\t\\t{} ({:.2f}%)'.format(num_val_data_walk, 100 * num_val_data_walk / len(val_reference_df)))\n",
    "    print('\\tBike:\\t\\t{} ({:.2f}%)'.format(num_val_data_bike, 100 * num_val_data_bike / len(val_reference_df)))\n",
    "    print('\\tStairs up:\\t{} ({:.2f}%)'.format(num_val_data_stairs_up, 100 * num_val_data_stairs_up / len(val_reference_df)))\n",
    "    print('\\tStairs down:\\t{} ({:.2f}%)'.format(num_val_data_stairs_down, 100 * num_val_data_stairs_down / len(val_reference_df)))\n",
    "\n",
    "\n",
    "print_dataset_statistics(train_reference_df, val_reference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         0         1    2        3         4    5         6         7  \\\n6785  -3.0 -3.000000 -3.0 -3.00000 -2.091919 -2.0 -2.829190 -3.000000   \n20108  5.0  5.000000  5.0  5.00000  5.000000  5.0  5.000000  5.000000   \n17854 -5.0 -4.733199 -4.0 -4.00000 -4.000000 -3.0 -3.000000 -3.214111   \n16603  4.0  4.000000  4.0  4.00000  4.000000  4.0  4.000000  4.000000   \n14823 -1.0 -1.000000 -1.0 -1.00000 -1.000000 -1.0 -1.153836 -2.000000   \n...    ...       ...  ...      ...       ...  ...       ...       ...   \n15377 -1.0 -1.000000 -1.0 -1.00000 -1.000000 -1.0 -1.000000 -1.000000   \n21602  5.0  5.000000  5.0  5.00000  5.000000  5.0  5.000000  5.000000   \n17730 -5.0 -5.000000 -5.0 -4.45692 -4.000000 -3.0 -3.998675 -4.000000   \n15725 -1.0 -1.000000 -1.0 -2.00000 -5.176727 -6.0 -7.000000 -5.000000   \n19966  0.0  0.000000  0.0  0.00000  0.000000  0.0  0.000000  0.000000   \n\n              8         9  ...  748  749  user    device  gt_bike  gt_sit  \\\n6785  -4.000000 -4.818164  ...  0.0  0.0     c      s3_2        0       0   \n20108  5.000000  5.000000  ...  0.0  0.0     i  nexus4_1        0       1   \n17854 -3.000000 -3.000000  ...  0.0  0.0     h  nexus4_1        0       0   \n16603  4.000000  4.000000  ...  0.0  0.0     g      s3_2        0       1   \n14823 -1.879435 -1.000000  ...  0.0  0.0     f  s3mini_1        1       0   \n...         ...       ...  ...  ...  ...   ...       ...      ...     ...   \n15377 -1.000000 -1.000000  ...  0.0  0.0     g  nexus4_2        0       0   \n21602  5.000000  5.000000  ...  0.0  0.0     i      s3_2        0       1   \n17730 -4.000000 -3.460956  ...  0.0  0.0     h  nexus4_1        0       0   \n15725 -4.000000 -4.000000  ...  0.0  0.0     g  nexus4_2        0       0   \n19966  0.000000  0.000000  ...  0.0  0.0     i  nexus4_1        0       0   \n\n       gt_stairsdown  gt_stairsup  gt_stand  gt_walk  \n6785               0            0         0        1  \n20108              0            0         0        0  \n17854              1            0         0        0  \n16603              0            0         0        0  \n14823              0            0         0        0  \n...              ...          ...       ...      ...  \n15377              0            0         1        0  \n21602              0            0         0        0  \n17730              0            0         0        1  \n15725              0            1         0        0  \n19966              0            0         1        0  \n\n[18071 rows x 758 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_reference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features: [[[-3.         -3.         -3.         ... -5.         -5.\n   -4.        ]\n  [ 0.          0.          0.         ... -0.28190104  0.\n    0.        ]\n  [ 5.          5.          5.90402832 ...  6.          6.64831543\n    7.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]\n\n [[ 5.          5.          5.         ...  5.          5.\n    5.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 8.          8.          8.         ...  8.          8.\n    8.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]\n\n [[-5.         -4.73319869 -4.         ... -3.         -3.\n   -3.        ]\n  [ 2.          1.26680131  2.         ... -1.         -1.\n   -1.        ]\n  [10.          8.          7.33589681 ...  9.          9.\n    9.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]\n\n ...\n\n [[-4.         -4.         -4.         ... -4.         -4.\n   -4.        ]\n  [ 1.          1.          1.         ...  0.          0.\n    0.        ]\n  [ 8.          9.          9.         ...  9.          9.\n    9.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]\n\n [[ 3.05450439  4.          3.         ...  4.          4.\n    4.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 9.          9.          9.         ...  9.          9.\n    9.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]\n\n [[ 1.          1.          1.         ...  1.          1.\n    1.        ]\n  [-2.         -2.         -1.99567871 ... -2.         -1.\n   -1.        ]\n  [ 7.          7.          7.         ...  7.66396484  8.\n    7.33168945]\n  [ 0.          0.          0.         ...  0.          0.\n    0.73662109]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]\n  [ 0.          0.          0.         ...  0.          0.\n    0.        ]]], Target: [[0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [0 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(reference_df, batch_size, shuffle, cache_file):\n",
    "    target = reference_df[['gt_sit','gt_stand','gt_walk','gt_bike','gt_stairsup','gt_stairsdown']].values.astype(int).tolist()\n",
    "\n",
    "    # RESHAPING DATAS\n",
    "    np_data = np.array(reference_df.iloc[:,0:750])\n",
    "    np_reshaped_data =np.reshape(np_data, (np_data.shape[0], 6, 125))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((np_reshaped_data, target))\n",
    "\n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "\n",
    "    # Shuffle\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(target))\n",
    "\n",
    "    # Repeat the dataset indefinitely\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "training_dataset = create_dataset(train_reference_df, batch_size=batch_size, shuffle=False, cache_file=None)\n",
    "val_dataset = create_dataset(val_reference_df, batch_size=batch_size, shuffle=False, cache_file=None)\n",
    "\n",
    "for feat, targ in training_dataset.take(1):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "\n",
    "train_steps = int(np.ceil(len(train_reference_df)/batch_size))\n",
    "val_steps = int(np.ceil(len(val_reference_df)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 6, 196)            392196    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2, 196)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              402432    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 800,778\n",
      "Trainable params: 800,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 1.1892 - accuracy: 0.6246 - val_loss: 0.5343 - val_accuracy: 0.8227\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.8360 - val_loss: 0.4063 - val_accuracy: 0.8613\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8856 - val_loss: 0.3068 - val_accuracy: 0.8965\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2673 - accuracy: 0.9028 - val_loss: 0.3217 - val_accuracy: 0.8880\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.2283 - accuracy: 0.9171 - val_loss: 0.3181 - val_accuracy: 0.8694\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1915 - accuracy: 0.9286 - val_loss: 0.2190 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9335 - val_loss: 0.2154 - val_accuracy: 0.9266\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1752 - accuracy: 0.9367 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1640 - accuracy: 0.9395 - val_loss: 0.2483 - val_accuracy: 0.9164\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1648 - accuracy: 0.9383 - val_loss: 0.1960 - val_accuracy: 0.9334\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1580 - accuracy: 0.9415 - val_loss: 0.2579 - val_accuracy: 0.9043\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1439 - accuracy: 0.9449 - val_loss: 0.2591 - val_accuracy: 0.9230\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1384 - accuracy: 0.9486 - val_loss: 0.1986 - val_accuracy: 0.9355\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1376 - accuracy: 0.9469 - val_loss: 0.2025 - val_accuracy: 0.9316\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1349 - accuracy: 0.9489 - val_loss: 0.1965 - val_accuracy: 0.9373\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1281 - accuracy: 0.9498 - val_loss: 0.1972 - val_accuracy: 0.9373\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9497 - val_loss: 0.2204 - val_accuracy: 0.9325\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9522 - val_loss: 0.1978 - val_accuracy: 0.9386\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1232 - accuracy: 0.9515 - val_loss: 0.2155 - val_accuracy: 0.9323\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 0.1308 - accuracy: 0.9509 - val_loss: 0.2180 - val_accuracy: 0.9377\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91a84f63a0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(6,125)))\n",
    "model.add(tf.keras.layers.Conv1D(196, 16, activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool1D(4, padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.05))\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam()\n",
    "loss_funct = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer = adam_optimizer, loss = loss_funct, metrics = [\"accuracy\"])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(training_dataset, epochs = 20, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}