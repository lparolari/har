{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_data_df = pd.read_csv('./datasets/heterogenity/original/dataset_50_2.5.csv', header=None)\n",
    "all_label_df = pd.read_csv('./datasets/heterogenity/original/dataset_labels_50_2.5.csv', names=[\"user\", \"model\", \"gt\"])\n",
    "\n",
    "dataset_df = pd.concat([all_data_df,all_label_df], axis=1)\n",
    "\n",
    "train_dataset_df = dataset_df.loc[(dataset_df['user'] != 'a') & (dataset_df['user'] != 'b')] \n",
    "train_reference_df = pd.get_dummies(train_dataset_df, columns=['gt'])\n",
    "\n",
    "test_dataset_df = dataset_df.loc[(dataset_df['user'] == 'a') | (dataset_df['user'] == 'b')] \n",
    "test_reference_df = pd.get_dummies(test_dataset_df, columns=['gt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN SET\n\tStand:\t\t2845 (16.34%)\n\tSit:\t\t3669 (21.08%)\n\tWalk:\t\t3923 (22.53%)\n\tBike:\t\t2341 (13.45%)\n\tStairs up:\t2589 (14.87%)\n\tStairs down:\t2042 (11.73%)\n\n\tPercentage of total\t17409 (77.07%)\n\nTEST SET\n\tStand:\t\t859 (16.58%)\n\tSit:\t\t961 (18.55%)\n\tWalk:\t\t1086 (20.97%)\n\tBike:\t\t815 (15.73%)\n\tStairs up:\t832 (16.06%)\n\tStairs down:\t627 (12.10%)\n\n\tPercentage of total\t5180 (22.93%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_dataset_statistics(train_reference_df, test_reference_df):\n",
    "\n",
    "    # Count the elements in the sets\n",
    "    num_train_data = (len(train_reference_df))\n",
    "    num_train_data_sit = sum(train_reference_df['gt_sit'] == 1)\n",
    "    num_train_data_stand = sum(train_reference_df['gt_stand'] == 1)\n",
    "    num_train_data_walk = sum(train_reference_df['gt_walk'] == 1)\n",
    "    num_train_data_bike = sum(train_reference_df['gt_bike'] == 1)\n",
    "    num_train_data_stairs_up = sum(train_reference_df['gt_stairsup'] == 1)\n",
    "    num_train_data_stairs_down = sum(train_reference_df['gt_stairsdown'] == 1)\n",
    "\n",
    "    num_test_data = (len(test_reference_df))\n",
    "    num_test_data_sit = sum(test_reference_df['gt_sit'] == 1)\n",
    "    num_test_data_stand = sum(test_reference_df['gt_stand'] == 1)\n",
    "    num_test_data_walk = sum(test_reference_df['gt_walk'] == 1)\n",
    "    num_test_data_bike = sum(test_reference_df['gt_bike'] == 1)\n",
    "    num_test_data_stairs_up = sum(test_reference_df['gt_stairsup'] == 1)\n",
    "    num_test_data_stairs_down = sum(test_reference_df['gt_stairsdown'] == 1)\n",
    "\n",
    "    total_df_data = num_train_data + num_test_data\n",
    "\n",
    "    print('TRAIN SET')\n",
    "    print('\\tStand:\\t\\t{} ({:.2f}%)'.format(num_train_data_stand, 100 * num_train_data_stand / len(train_reference_df)))\n",
    "    print('\\tSit:\\t\\t{} ({:.2f}%)'.format(num_train_data_sit, 100 * num_train_data_sit / len(train_reference_df)))\n",
    "    print('\\tWalk:\\t\\t{} ({:.2f}%)'.format(num_train_data_walk, 100 * num_train_data_walk / len(train_reference_df)))\n",
    "    print('\\tBike:\\t\\t{} ({:.2f}%)'.format(num_train_data_bike, 100 * num_train_data_bike / len(train_reference_df)))\n",
    "    print('\\tStairs up:\\t{} ({:.2f}%)'.format(num_train_data_stairs_up, 100 * num_train_data_stairs_up / len(train_reference_df)))\n",
    "    print('\\tStairs down:\\t{} ({:.2f}%)'.format(num_train_data_stairs_down, 100 * num_train_data_stairs_down / len(train_reference_df)))\n",
    "    print('')\n",
    "    print('\\tPercentage of total\\t{} ({:.2f}%)'.format(num_train_data, 100 * num_train_data/ total_df_data))\n",
    "    print('')\n",
    "\n",
    "    print('TEST SET')\n",
    "    \n",
    "    print('\\tStand:\\t\\t{} ({:.2f}%)'.format(num_test_data_stand, 100 * num_test_data_stand / len(test_reference_df)))\n",
    "    print('\\tSit:\\t\\t{} ({:.2f}%)'.format(num_test_data_sit, 100 * num_test_data_sit / len(test_reference_df)))\n",
    "    print('\\tWalk:\\t\\t{} ({:.2f}%)'.format(num_test_data_walk, 100 * num_test_data_walk / len(test_reference_df)))\n",
    "    print('\\tBike:\\t\\t{} ({:.2f}%)'.format(num_test_data_bike, 100 * num_test_data_bike / len(test_reference_df)))\n",
    "    print('\\tStairs up:\\t{} ({:.2f}%)'.format(num_test_data_stairs_up, 100 * num_test_data_stairs_up / len(test_reference_df)))\n",
    "    print('\\tStairs down:\\t{} ({:.2f}%)'.format(num_test_data_stairs_down, 100 * num_test_data_stairs_down / len(test_reference_df)))\n",
    "    print('')\n",
    "    print('\\tPercentage of total\\t{} ({:.2f}%)'.format(num_test_data, 100 * num_test_data/ total_df_data))\n",
    "\n",
    "\n",
    "print_dataset_statistics(train_reference_df, test_reference_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              0    1         2         3         4         5         6  \\\n2574  -1.000000 -1.0 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n2575  -1.000000 -1.0 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n2576  -1.000000 -1.0 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n2577  -1.000000 -1.0 -1.000000 -1.000000 -2.000000 -1.304657 -0.642802   \n2578  -1.000000 -1.0 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n...         ...  ...       ...       ...       ...       ...       ...   \n22584 -2.313599 -2.0 -2.000000 -2.000000 -2.000000 -1.000000 -1.000000   \n22585 -1.493705 -1.0 -1.000000  0.000000  0.000000  0.000000  0.000000   \n22586  0.000000  0.0  0.000000  0.000000 -1.000000 -1.000000  0.000000   \n22587  0.000000  0.0  0.000000  0.720006  0.707711 -0.721697 -4.587960   \n22588 -4.646136 -5.0 -4.175241 -3.000000 -3.000000 -3.000000 -2.171858   \n\n              7         8         9  ...  748  749  user     model  gt_bike  \\\n2574  -1.000000 -1.000000 -1.000000  ...  0.0  0.0     b  nexus4_1        0   \n2575  -1.000000 -1.000000 -1.000000  ...  0.0  0.0     b  nexus4_1        0   \n2576  -1.000000 -1.000000 -1.000000  ...  0.0  0.0     b  nexus4_1        0   \n2577  -0.175890 -1.000000 -1.000000  ...  0.0  0.0     b  nexus4_1        0   \n2578  -1.000000 -1.000000 -1.000000  ...  0.0  0.0     b  nexus4_1        0   \n...         ...       ...       ...  ...  ...  ...   ...       ...      ...   \n22584 -1.000000 -0.306832  0.000000  ...  0.0  0.0     i  s3mini_2        0   \n22585  0.000000  0.000000  0.000000  ...  0.0  0.0     i  s3mini_2        0   \n22586  0.000000  1.000000  0.380511  ...  0.0  0.0     i  s3mini_2        0   \n22587 -6.000000 -4.724040 -3.346348  ...  0.0  0.0     i  s3mini_2        0   \n22588 -1.599592 -1.829834 -2.000000  ...  0.0  0.0     i  s3mini_2        0   \n\n       gt_sit  gt_stairsdown  gt_stairsup  gt_stand  gt_walk  \n2574        0              0            0         1        0  \n2575        0              0            0         1        0  \n2576        0              0            0         1        0  \n2577        0              0            0         1        0  \n2578        0              0            0         1        0  \n...       ...            ...          ...       ...      ...  \n22584       0              0            0         0        1  \n22585       0              0            0         0        1  \n22586       0              0            0         0        1  \n22587       0              0            0         0        1  \n22588       0              0            0         0        1  \n\n[20015 rows x 758 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_reference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6.3         5.6         5.6         2.9         2.76405499  2.76405499\n   2.5         2.4         2.4        10.26614733  0.5         0.\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         1.          0.5         0.          1.          0.5\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         0.          1.          0.5         0.5         0.5\n   0.5         0.5         0.5         0.5       ]\n [ 5.5         5.5         5.5         2.87228132  2.87228132  2.87228132\n   2.5         2.5         2.5         9.52627944  0.5         0.5\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         0.5         0.5         0.5         0.5         0.5\n   0.5         0.5         0.5         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "def extract_basic_features(acc_x, acc_y, acc_z):\n",
    "    # prova = np.array(np.apply_along_axis(np.histogram, 1, acc_x)[0]).reshape(2,1)\n",
    "\n",
    "    np_acc_x = np.array(acc_x)\n",
    "    np_acc_y = np.array(acc_y)\n",
    "    np_acc_z = np.array(acc_z)\n",
    "\n",
    "    mean_x = np.expand_dims(np.mean(np_acc_x, axis=1), axis=0).T \n",
    "    mean_y = np.expand_dims(np.mean(np_acc_y, axis=1), axis=0).T \n",
    "    mean_z = np.expand_dims(np.mean(np_acc_z, axis=1), axis=0).T \n",
    "\n",
    "    basic_features = np.concatenate( (\n",
    "        # insert MEANS \n",
    "        mean_x,\n",
    "        mean_y,\n",
    "        mean_z,\n",
    "\n",
    "        # insert STD\n",
    "        np.expand_dims(np.std(np_acc_x, axis=1), axis=0).T, \n",
    "        np.expand_dims(np.std(np_acc_y, axis=1), axis=0).T, \n",
    "        np.expand_dims(np.std(np_acc_z, axis=1), axis=0).T, \n",
    "\n",
    "        # insert sum of thew absolute values\n",
    "        np.expand_dims(np.mean(abs(np_acc_x - mean_x), axis=1), axis=1),\n",
    "        np.expand_dims(np.mean(abs(np_acc_y - mean_y), axis=1), axis=1),\n",
    "        np.expand_dims(np.mean(abs(np_acc_z - mean_z), axis=1), axis=1),\n",
    "\n",
    "        np.expand_dims(np.mean( np.sqrt( np.power(np_acc_x, 2) + np.power(np_acc_y,2) + np.power(np_acc_z, 2) ), axis=1), axis=0).T\n",
    "        \n",
    "    ), axis=1).tolist()\n",
    "\n",
    "    for i in range(0, len(acc_x)):\n",
    "        bins_x, centers_x = np.histogram(acc_x[i], bins=10)\n",
    "        bins_y, centers_y = np.histogram(acc_y[i], bins=10)\n",
    "        bins_z, centers_z = np.histogram(acc_z[i], bins=10)\n",
    "\n",
    "        basic_features[i].extend(bins_x / len(acc_x))\n",
    "        basic_features[i].extend(bins_y / len(acc_y))\n",
    "        basic_features[i].extend(bins_z / len(acc_z))\n",
    "\n",
    "    return basic_features\n",
    "\n",
    "prova_feat = np.array(extract_basic_features( [[1,10,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10]] , [[1,3,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10]], [[1,3,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10]]))\n",
    "\n",
    "print(prova_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features: {'input_1': <tf.Tensor: shape=(128, 6, 125), dtype=float64, numpy=\narray([[[-5.        , -5.        , -4.        , ..., -7.        ,\n         -7.        , -7.        ],\n        [ 0.        , -0.01291504, -1.        , ...,  0.        ,\n         -0.82843572, -0.18791504],\n        [ 4.        ,  4.        ,  4.01247337, ...,  9.08952637,\n          7.17156428,  5.18791504],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.02744141, ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]],\n\n       [[-2.        , -2.        , -2.        , ..., -1.        ,\n         -0.54345703, -0.8388916 ],\n        [ 0.        ,  0.        , -1.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 7.        ,  7.        ,  7.        , ...,  7.        ,\n          7.        ,  7.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 2.        ,  2.        ,  2.        , ...,  0.        ,\n          0.        ,  0.        ]],\n\n       [[ 0.        ,  0.        ,  0.        , ..., -2.        ,\n         -2.        , -1.        ],\n        [ 1.        ,  0.97827148,  0.        , ...,  0.        ,\n          0.24777832,  1.        ],\n        [ 8.        ,  8.02172852,  9.        , ..., 10.        ,\n         10.        ,  9.80861253],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]],\n\n       ...,\n\n       [[-1.        , -0.89125977, -1.        , ..., -1.        ,\n         -1.        ,  0.        ],\n        [-1.        ,  0.        ,  0.        , ...,  3.        ,\n          3.        ,  2.        ],\n        [ 7.        ,  8.        ,  8.69780273, ...,  9.        ,\n          8.38409424,  7.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]],\n\n       [[ 0.        ,  0.        ,  0.        , ..., -3.42250279,\n         -2.        , -2.        ],\n        [ 2.        ,  1.        ,  0.        , ..., -1.        ,\n          0.        ,  0.21325684],\n        [ 9.        ,  9.        , 10.        , ...,  9.        ,\n          9.21298828,  9.78674316],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]],\n\n       [[ 0.        ,  0.        ,  0.        , ..., -1.        ,\n         -1.        , -1.        ],\n        [-1.        , -1.        , -1.        , ...,  0.        ,\n         -1.        , -1.        ],\n        [ 8.        ,  8.        ,  9.        , ...,  9.42258301,\n         10.        , 10.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n          0.        ,  0.        ]]])>, 'input_2': <tf.Tensor: shape=(128, 40), dtype=float64, numpy=\narray([[-4.30556687e+00, -1.52089205e-01,  7.97674070e+00, ...,\n         5.74415532e-04,  5.16973979e-04,  2.29766213e-04],\n       [-1.54585843e+00,  1.26186342e-01,  8.69497170e+00, ...,\n         5.74415532e-05,  5.74415532e-05,  5.74415532e-05],\n       [-1.11375345e+00,  1.40306472e-01,  9.03385935e+00, ...,\n         9.19064852e-04,  2.87207766e-04,  1.72324660e-04],\n       ...,\n       [-3.81029034e-01,  5.05769862e-01,  9.64729479e+00, ...,\n         2.29766213e-04,  9.19064852e-04,  8.61623298e-04],\n       [-1.77053390e+00,  2.90402618e-01,  8.88965268e+00, ...,\n         4.02090873e-04,  3.44649319e-04,  4.02090873e-04],\n       [-6.74198803e-01, -6.95270756e-02,  8.94054722e+00, ...,\n         1.55092194e-03,  0.00000000e+00,  1.14883106e-04]])>}, Target: [[0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 0 0 0 1]\n [0 0 0 0 1 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 0 1]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 1 0 0]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [0 0 0 1 0 0]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 0 0 0 1]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [0 0 0 0 1 0]\n [0 0 0 1 0 0]\n [0 1 0 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [0 0 0 0 1 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 1 0 0 0 0]\n [0 0 0 0 1 0]\n [0 1 0 0 0 0]\n [0 1 0 0 0 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 0 1 0]\n [0 0 1 0 0 0]\n [1 0 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 1 0 0 0 0]\n [0 0 0 1 0 0]\n [0 0 1 0 0 0]\n [0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(reference_df, batch_size, shuffle, cache_file, center_data=False):\n",
    "    target = reference_df[['gt_sit','gt_stand','gt_walk','gt_bike','gt_stairsup','gt_stairsdown']].values.astype(int).tolist()\n",
    "\n",
    "    # RESHAPING DATAS\n",
    "    np_data = np.array(reference_df.iloc[:,0:750])\n",
    "\n",
    "    np_reshaped_data = np.reshape(np_data.copy(), (np_data.shape[0], 6, 125))\n",
    "\n",
    "    # Data centering\n",
    "    if center_data:\n",
    "        for i in range(len(np_reshaped_data)):\n",
    "            window = np_reshaped_data[i]\n",
    "            means = np.mean(window, axis=1)\n",
    "            centered_acc = np.array(([window[j] - means[j] for j in range(3)]))\n",
    "            np_reshaped_data[i] = np.concatenate((centered_acc, window[3:]), axis=0)\n",
    "             \n",
    "    \n",
    "    # Extract manual features\n",
    "    np_basic_features = np.array(extract_basic_features(np_data[:, 0:125], np_data[:, 125:250], np_data[:, 250: 375]))\n",
    "\n",
    "    # Create dataset obj\n",
    "    dataset = tf.data.Dataset.from_tensor_slices( ({\"input_1\": np_reshaped_data, \"input_2\": np_basic_features}, target) )\n",
    "\n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "\n",
    "    # Shuffle\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(target))\n",
    "\n",
    "    # Repeat the dataset indefinitely\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "training_dataset = create_dataset(train_reference_df, batch_size=batch_size, shuffle=True, cache_file=None)\n",
    "val_dataset = create_dataset(test_reference_df, batch_size=batch_size, shuffle=True, cache_file=None)\n",
    "\n",
    "for train, targ in training_dataset.take(1):\n",
    "  print ('Features: {}, Target: {}'.format(train, targ))\n",
    "\n",
    "train_steps = int(np.ceil(len(train_reference_df)/batch_size))\n",
    "val_steps = int(np.ceil(len(test_reference_df)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"OurModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 125)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 6, 196)       392196      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2, 196)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 392)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 432)]        0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         443392      tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            6150        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 841,738\n",
      "Trainable params: 841,738\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    l2_reg = 5e-4\n",
    "\n",
    "    encoder = tf.keras.models.load_model('encoder.h5')\n",
    "\n",
    "    # NOT TRAIN THE MODEL\n",
    "    encoder.trainable = False\n",
    "\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    training_input = tf.keras.Input(shape=input_shape, dtype=tf.float32, name='input_1')\n",
    "    basic_feat_input = tf.keras.Input(shape=40, dtype=tf.float32, name='input_2')\n",
    "\n",
    "    CNN = tf.keras.layers.Conv1D(196, 16, activation='relu', padding='same')(training_input)\n",
    "    CNN = tf.keras.layers.MaxPool1D(4, padding='same')(CNN)\n",
    "    \n",
    "    feautures_CCN = tf.keras.layers.Flatten()(CNN)\n",
    "    \n",
    "    featuers_encoder = encoder(training_input)\n",
    "\n",
    "    features = tf.concat((feautures_CCN, basic_feat_input), 1) \n",
    "\n",
    "    #features = tf.concat((feautures_CCN), 1) \n",
    "\n",
    "    FFNN = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2_reg), activity_regularizer=tf.keras.regularizers.L2(l2_reg))(features)\n",
    "    FFNN = tf.keras.layers.Dropout(0.05)(FFNN)\n",
    "    model_output = tf.keras.layers.Dense(6, activation='softmax')(FFNN)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [training_input, basic_feat_input], outputs = model_output, name='OurModel')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model((6,125))\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "loss_funct = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer = adam_optimizer, loss = loss_funct, metrics = [\"accuracy\"])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 1.1658 - accuracy: 0.7556 - val_loss: 1.1420 - val_accuracy: 0.6675\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.6081 - accuracy: 0.9053 - val_loss: 1.1048 - val_accuracy: 0.6782\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.4686 - accuracy: 0.9449 - val_loss: 1.0784 - val_accuracy: 0.7151\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.9624 - val_loss: 1.0251 - val_accuracy: 0.7338\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3349 - accuracy: 0.9706 - val_loss: 1.0648 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.3024 - accuracy: 0.9750 - val_loss: 1.1817 - val_accuracy: 0.6860\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.2690 - accuracy: 0.9800 - val_loss: 1.2287 - val_accuracy: 0.7462\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.2390 - accuracy: 0.9843 - val_loss: 1.1411 - val_accuracy: 0.7281\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.2188 - accuracy: 0.9857 - val_loss: 1.1978 - val_accuracy: 0.7069\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1985 - accuracy: 0.9874 - val_loss: 1.1374 - val_accuracy: 0.7481\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1761 - accuracy: 0.9917 - val_loss: 1.2255 - val_accuracy: 0.7355\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1630 - accuracy: 0.9924 - val_loss: 1.2869 - val_accuracy: 0.7559\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1475 - accuracy: 0.9944 - val_loss: 1.3341 - val_accuracy: 0.7506\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1377 - accuracy: 0.9932 - val_loss: 1.1024 - val_accuracy: 0.6843\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1300 - accuracy: 0.9933 - val_loss: 1.1580 - val_accuracy: 0.6907\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1164 - accuracy: 0.9956 - val_loss: 1.2535 - val_accuracy: 0.7212\n",
      "Epoch 17/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.9934 - val_loss: 1.0678 - val_accuracy: 0.7096\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1094 - accuracy: 0.9929 - val_loss: 1.4277 - val_accuracy: 0.6894\n",
      "Epoch 19/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.1061 - accuracy: 0.9921 - val_loss: 1.5159 - val_accuracy: 0.7369\n",
      "Epoch 20/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9895 - val_loss: 1.4746 - val_accuracy: 0.7117\n",
      "Epoch 21/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.0876 - accuracy: 0.9949 - val_loss: 1.6021 - val_accuracy: 0.6635\n",
      "Epoch 22/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.0776 - accuracy: 0.9961 - val_loss: 1.4176 - val_accuracy: 0.6995\n",
      "Epoch 23/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9976 - val_loss: 1.4265 - val_accuracy: 0.7062\n",
      "Epoch 24/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.0628 - accuracy: 0.9964 - val_loss: 1.4768 - val_accuracy: 0.7473\n",
      "Epoch 25/100\n",
      "137/137 [==============================] - 1s 7ms/step - loss: 0.0673 - accuracy: 0.9942 - val_loss: 1.4312 - val_accuracy: 0.7085\n",
      "Epoch 26/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.1098 - accuracy: 0.9812 - val_loss: 1.3682 - val_accuracy: 0.7071\n",
      "Epoch 27/100\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9913 - val_loss: 1.7571 - val_accuracy: 0.6654\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c7c6b2e50>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./models/checkpoint', save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model.fit(training_dataset, epochs = 100, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps,  callbacks = [early_stopping_callback, model_checkpoint_callback])"
   ]
  },
  {
   "source": [
    "# K-FOLD CROSS VALIDATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 1.1589 - categorical_accuracy: 0.7559 - precision_13: 0.8516 - recall_13: 0.6313 - val_loss: 1.3999 - val_categorical_accuracy: 0.6425 - val_precision_13: 0.7185 - val_recall_13: 0.3456\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5694 - categorical_accuracy: 0.9143 - precision_13: 0.9359 - recall_13: 0.8878 - val_loss: 1.3832 - val_categorical_accuracy: 0.5413 - val_precision_13: 0.5096 - val_recall_13: 0.3940\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4373 - categorical_accuracy: 0.9487 - precision_13: 0.9584 - recall_13: 0.9355 - val_loss: 1.1551 - val_categorical_accuracy: 0.5807 - val_precision_13: 0.7804 - val_recall_13: 0.5446\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3614 - categorical_accuracy: 0.9641 - precision_13: 0.9701 - recall_13: 0.9575 - val_loss: 1.3867 - val_categorical_accuracy: 0.5889 - val_precision_13: 0.5846 - val_recall_13: 0.4937\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3159 - categorical_accuracy: 0.9711 - precision_13: 0.9758 - recall_13: 0.9666 - val_loss: 1.5212 - val_categorical_accuracy: 0.5789 - val_precision_13: 0.5868 - val_recall_13: 0.5521\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2782 - categorical_accuracy: 0.9766 - precision_13: 0.9803 - recall_13: 0.9731 - val_loss: 1.5178 - val_categorical_accuracy: 0.5268 - val_precision_13: 0.5699 - val_recall_13: 0.4762\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2449 - categorical_accuracy: 0.9817 - precision_13: 0.9847 - recall_13: 0.9786 - val_loss: 1.9396 - val_categorical_accuracy: 0.4967 - val_precision_13: 0.5165 - val_recall_13: 0.4650\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2218 - categorical_accuracy: 0.9854 - precision_13: 0.9871 - recall_13: 0.9832 - val_loss: 2.1314 - val_categorical_accuracy: 0.5231 - val_precision_13: 0.5361 - val_recall_13: 0.5052\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2080 - categorical_accuracy: 0.9831 - precision_13: 0.9849 - recall_13: 0.9807 - val_loss: 1.6525 - val_categorical_accuracy: 0.6343 - val_precision_13: 0.6398 - val_recall_13: 0.6131\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1829 - categorical_accuracy: 0.9877 - precision_13: 0.9891 - recall_13: 0.9856 - val_loss: 1.5550 - val_categorical_accuracy: 0.5469 - val_precision_13: 0.5638 - val_recall_13: 0.4818\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1649 - categorical_accuracy: 0.9890 - precision_13: 0.9906 - recall_13: 0.9877 - val_loss: 2.1708 - val_categorical_accuracy: 0.5216 - val_precision_13: 0.5379 - val_recall_13: 0.5015\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1485 - categorical_accuracy: 0.9907 - precision_13: 0.9915 - recall_13: 0.9896 - val_loss: 1.4559 - val_categorical_accuracy: 0.5353 - val_precision_13: 0.5891 - val_recall_13: 0.5167\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1419 - categorical_accuracy: 0.9899 - precision_13: 0.9908 - recall_13: 0.9889 - val_loss: 2.0724 - val_categorical_accuracy: 0.5331 - val_precision_13: 0.5445 - val_recall_13: 0.5149\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1341 - categorical_accuracy: 0.9891 - precision_13: 0.9903 - recall_13: 0.9879 - val_loss: 1.9648 - val_categorical_accuracy: 0.5580 - val_precision_13: 0.5576 - val_recall_13: 0.5420\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1211 - categorical_accuracy: 0.9906 - precision_13: 0.9914 - recall_13: 0.9898 - val_loss: 2.3552 - val_categorical_accuracy: 0.5052 - val_precision_13: 0.5464 - val_recall_13: 0.4970\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1080 - categorical_accuracy: 0.9924 - precision_13: 0.9932 - recall_13: 0.9918 - val_loss: 2.4123 - val_categorical_accuracy: 0.6116 - val_precision_13: 0.6139 - val_recall_13: 0.5867\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1080 - categorical_accuracy: 0.9896 - precision_13: 0.9905 - recall_13: 0.9886 - val_loss: 2.0910 - val_categorical_accuracy: 0.5119 - val_precision_13: 0.5693 - val_recall_13: 0.4948\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1096 - categorical_accuracy: 0.9880 - precision_13: 0.9891 - recall_13: 0.9866 - val_loss: 2.1816 - val_categorical_accuracy: 0.5327 - val_precision_13: 0.5526 - val_recall_13: 0.5179\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0958 - categorical_accuracy: 0.9902 - precision_13: 0.9909 - recall_13: 0.9892 - val_loss: 2.0046 - val_categorical_accuracy: 0.5153 - val_precision_13: 0.5227 - val_recall_13: 0.5045\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0802 - categorical_accuracy: 0.9938 - precision_13: 0.9941 - recall_13: 0.9930 - val_loss: 2.1457 - val_categorical_accuracy: 0.5033 - val_precision_13: 0.5471 - val_recall_13: 0.4903\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0717 - categorical_accuracy: 0.9945 - precision_13: 0.9948 - recall_13: 0.9941 - val_loss: 2.0365 - val_categorical_accuracy: 0.5141 - val_precision_13: 0.5570 - val_recall_13: 0.4911\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0681 - categorical_accuracy: 0.9940 - precision_13: 0.9944 - recall_13: 0.9936 - val_loss: 1.5334 - val_categorical_accuracy: 0.6124 - val_precision_13: 0.6162 - val_recall_13: 0.5997\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0761 - categorical_accuracy: 0.9905 - precision_13: 0.9910 - recall_13: 0.9899 - val_loss: 2.9924 - val_categorical_accuracy: 0.4721 - val_precision_13: 0.4914 - val_recall_13: 0.4654\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0920 - categorical_accuracy: 0.9854 - precision_13: 0.9864 - recall_13: 0.9837 - val_loss: 1.9204 - val_categorical_accuracy: 0.5201 - val_precision_13: 0.5335 - val_recall_13: 0.4970\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0726 - categorical_accuracy: 0.9905 - precision_13: 0.9914 - recall_13: 0.9900 - val_loss: 2.7194 - val_categorical_accuracy: 0.5309 - val_precision_13: 0.5775 - val_recall_13: 0.5156\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4099 - categorical_accuracy: 0.6391 - precision_13: 0.7131 - recall_13: 0.3411\n",
      "Accuracy: 0.6391369104385376\n",
      "Precision: 0.7130637764930725\n",
      "Recall: 0.3411458432674408\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.2241 - categorical_accuracy: 0.7273 - precision_14: 0.8265 - recall_14: 0.5836 - val_loss: 0.8084 - val_categorical_accuracy: 0.8371 - val_precision_14: 0.8838 - val_recall_14: 0.7839\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6362 - categorical_accuracy: 0.8908 - precision_14: 0.9150 - recall_14: 0.8574 - val_loss: 0.5835 - val_categorical_accuracy: 0.8876 - val_precision_14: 0.8996 - val_recall_14: 0.8564\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4992 - categorical_accuracy: 0.9228 - precision_14: 0.9369 - recall_14: 0.9074 - val_loss: 0.5845 - val_categorical_accuracy: 0.8705 - val_precision_14: 0.8884 - val_recall_14: 0.8531\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4252 - categorical_accuracy: 0.9396 - precision_14: 0.9489 - recall_14: 0.9296 - val_loss: 0.5317 - val_categorical_accuracy: 0.9007 - val_precision_14: 0.9070 - val_recall_14: 0.8858\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3698 - categorical_accuracy: 0.9493 - precision_14: 0.9559 - recall_14: 0.9420 - val_loss: 0.5365 - val_categorical_accuracy: 0.9025 - val_precision_14: 0.9114 - val_recall_14: 0.8914\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3273 - categorical_accuracy: 0.9563 - precision_14: 0.9619 - recall_14: 0.9511 - val_loss: 0.4528 - val_categorical_accuracy: 0.9126 - val_precision_14: 0.9181 - val_recall_14: 0.9051\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3037 - categorical_accuracy: 0.9585 - precision_14: 0.9628 - recall_14: 0.9543 - val_loss: 0.5040 - val_categorical_accuracy: 0.9040 - val_precision_14: 0.9104 - val_recall_14: 0.8958\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2755 - categorical_accuracy: 0.9612 - precision_14: 0.9648 - recall_14: 0.9571 - val_loss: 0.4038 - val_categorical_accuracy: 0.9286 - val_precision_14: 0.9314 - val_recall_14: 0.9245\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2595 - categorical_accuracy: 0.9631 - precision_14: 0.9667 - recall_14: 0.9596 - val_loss: 0.3713 - val_categorical_accuracy: 0.9234 - val_precision_14: 0.9266 - val_recall_14: 0.9208\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2318 - categorical_accuracy: 0.9676 - precision_14: 0.9700 - recall_14: 0.9656 - val_loss: 0.3971 - val_categorical_accuracy: 0.9219 - val_precision_14: 0.9239 - val_recall_14: 0.9163\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2122 - categorical_accuracy: 0.9686 - precision_14: 0.9704 - recall_14: 0.9669 - val_loss: 0.3993 - val_categorical_accuracy: 0.9185 - val_precision_14: 0.9224 - val_recall_14: 0.9148\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2034 - categorical_accuracy: 0.9694 - precision_14: 0.9710 - recall_14: 0.9676 - val_loss: 0.4255 - val_categorical_accuracy: 0.9062 - val_precision_14: 0.9117 - val_recall_14: 0.9025\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1913 - categorical_accuracy: 0.9688 - precision_14: 0.9706 - recall_14: 0.9669 - val_loss: 0.3405 - val_categorical_accuracy: 0.9178 - val_precision_14: 0.9212 - val_recall_14: 0.9133\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1732 - categorical_accuracy: 0.9722 - precision_14: 0.9734 - recall_14: 0.9709 - val_loss: 0.3162 - val_categorical_accuracy: 0.9267 - val_precision_14: 0.9307 - val_recall_14: 0.9237\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1624 - categorical_accuracy: 0.9730 - precision_14: 0.9743 - recall_14: 0.9716 - val_loss: 0.3636 - val_categorical_accuracy: 0.9208 - val_precision_14: 0.9220 - val_recall_14: 0.9100\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1623 - categorical_accuracy: 0.9683 - precision_14: 0.9698 - recall_14: 0.9662 - val_loss: 0.3619 - val_categorical_accuracy: 0.9081 - val_precision_14: 0.9142 - val_recall_14: 0.9033\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1776 - categorical_accuracy: 0.9621 - precision_14: 0.9645 - recall_14: 0.9599 - val_loss: 0.3607 - val_categorical_accuracy: 0.9122 - val_precision_14: 0.9180 - val_recall_14: 0.9074\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1522 - categorical_accuracy: 0.9692 - precision_14: 0.9706 - recall_14: 0.9673 - val_loss: 0.3627 - val_categorical_accuracy: 0.9211 - val_precision_14: 0.9247 - val_recall_14: 0.9185\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1426 - categorical_accuracy: 0.9722 - precision_14: 0.9733 - recall_14: 0.9707 - val_loss: 0.3789 - val_categorical_accuracy: 0.9118 - val_precision_14: 0.9165 - val_recall_14: 0.9107\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1329 - categorical_accuracy: 0.9720 - precision_14: 0.9732 - recall_14: 0.9708 - val_loss: 0.3354 - val_categorical_accuracy: 0.9267 - val_precision_14: 0.9292 - val_recall_14: 0.9234\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1183 - categorical_accuracy: 0.9756 - precision_14: 0.9763 - recall_14: 0.9748 - val_loss: 0.3377 - val_categorical_accuracy: 0.9204 - val_precision_14: 0.9219 - val_recall_14: 0.9174\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1136 - categorical_accuracy: 0.9746 - precision_14: 0.9757 - recall_14: 0.9737 - val_loss: 0.3244 - val_categorical_accuracy: 0.9163 - val_precision_14: 0.9205 - val_recall_14: 0.9133\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1125 - categorical_accuracy: 0.9733 - precision_14: 0.9745 - recall_14: 0.9724 - val_loss: 0.3139 - val_categorical_accuracy: 0.9185 - val_precision_14: 0.9211 - val_recall_14: 0.9167\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1078 - categorical_accuracy: 0.9747 - precision_14: 0.9759 - recall_14: 0.9738 - val_loss: 0.3274 - val_categorical_accuracy: 0.9226 - val_precision_14: 0.9256 - val_recall_14: 0.9211\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1044 - categorical_accuracy: 0.9736 - precision_14: 0.9745 - recall_14: 0.9724 - val_loss: 0.2902 - val_categorical_accuracy: 0.9129 - val_precision_14: 0.9162 - val_recall_14: 0.9107\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1025 - categorical_accuracy: 0.9726 - precision_14: 0.9733 - recall_14: 0.9717 - val_loss: 0.2898 - val_categorical_accuracy: 0.9278 - val_precision_14: 0.9304 - val_recall_14: 0.9249\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1257 - categorical_accuracy: 0.9664 - precision_14: 0.9680 - recall_14: 0.9648 - val_loss: 0.2928 - val_categorical_accuracy: 0.9289 - val_precision_14: 0.9292 - val_recall_14: 0.9275\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1278 - categorical_accuracy: 0.9645 - precision_14: 0.9658 - recall_14: 0.9622 - val_loss: 0.2456 - val_categorical_accuracy: 0.9349 - val_precision_14: 0.9359 - val_recall_14: 0.9342\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1039 - categorical_accuracy: 0.9719 - precision_14: 0.9730 - recall_14: 0.9708 - val_loss: 0.2974 - val_categorical_accuracy: 0.9271 - val_precision_14: 0.9307 - val_recall_14: 0.9249\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2407 - categorical_accuracy: 0.9356 - precision_14: 0.9366 - recall_14: 0.9349\n",
      "Accuracy: 0.9356398582458496\n",
      "Precision: 0.9366381168365479\n",
      "Recall: 0.9348958134651184\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 9ms/step - loss: 1.1463 - categorical_accuracy: 0.7565 - precision_15: 0.8516 - recall_15: 0.6233 - val_loss: 1.5977 - val_categorical_accuracy: 0.4466 - val_precision_15: 0.4736 - val_recall_15: 0.3385\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.5783 - categorical_accuracy: 0.9013 - precision_15: 0.9256 - recall_15: 0.8701 - val_loss: 1.7499 - val_categorical_accuracy: 0.4896 - val_precision_15: 0.4895 - val_recall_15: 0.4036\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.4536 - categorical_accuracy: 0.9318 - precision_15: 0.9462 - recall_15: 0.9171 - val_loss: 1.3938 - val_categorical_accuracy: 0.5521 - val_precision_15: 0.5462 - val_recall_15: 0.4722\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.3805 - categorical_accuracy: 0.9488 - precision_15: 0.9558 - recall_15: 0.9399 - val_loss: 1.7000 - val_categorical_accuracy: 0.5564 - val_precision_15: 0.5604 - val_recall_15: 0.5156\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.3382 - categorical_accuracy: 0.9550 - precision_15: 0.9618 - recall_15: 0.9478 - val_loss: 1.7450 - val_categorical_accuracy: 0.5286 - val_precision_15: 0.5370 - val_recall_15: 0.4696\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.3081 - categorical_accuracy: 0.9578 - precision_15: 0.9629 - recall_15: 0.9518 - val_loss: 1.5371 - val_categorical_accuracy: 0.5074 - val_precision_15: 0.5036 - val_recall_15: 0.4557\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2688 - categorical_accuracy: 0.9639 - precision_15: 0.9682 - recall_15: 0.9596 - val_loss: 1.4458 - val_categorical_accuracy: 0.5534 - val_precision_15: 0.5640 - val_recall_15: 0.5221\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2438 - categorical_accuracy: 0.9681 - precision_15: 0.9702 - recall_15: 0.9653 - val_loss: 1.1335 - val_categorical_accuracy: 0.6319 - val_precision_15: 0.6792 - val_recall_15: 0.5964\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2252 - categorical_accuracy: 0.9692 - precision_15: 0.9720 - recall_15: 0.9667 - val_loss: 1.1755 - val_categorical_accuracy: 0.5812 - val_precision_15: 0.6672 - val_recall_15: 0.5508\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.2165 - categorical_accuracy: 0.9683 - precision_15: 0.9705 - recall_15: 0.9656 - val_loss: 1.1791 - val_categorical_accuracy: 0.5786 - val_precision_15: 0.6573 - val_recall_15: 0.5495\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1923 - categorical_accuracy: 0.9711 - precision_15: 0.9727 - recall_15: 0.9689 - val_loss: 1.3434 - val_categorical_accuracy: 0.5443 - val_precision_15: 0.6028 - val_recall_15: 0.5104\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1784 - categorical_accuracy: 0.9733 - precision_15: 0.9748 - recall_15: 0.9712 - val_loss: 1.3694 - val_categorical_accuracy: 0.5786 - val_precision_15: 0.6098 - val_recall_15: 0.5629\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.1669 - categorical_accuracy: 0.9729 - precision_15: 0.9740 - recall_15: 0.9714 - val_loss: 1.2452 - val_categorical_accuracy: 0.5569 - val_precision_15: 0.6084 - val_recall_15: 0.5373\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1539 - categorical_accuracy: 0.9738 - precision_15: 0.9755 - recall_15: 0.9718 - val_loss: 1.2696 - val_categorical_accuracy: 0.5595 - val_precision_15: 0.6241 - val_recall_15: 0.5425\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1496 - categorical_accuracy: 0.9721 - precision_15: 0.9736 - recall_15: 0.9707 - val_loss: 1.2178 - val_categorical_accuracy: 0.5503 - val_precision_15: 0.6076 - val_recall_15: 0.5282\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1447 - categorical_accuracy: 0.9712 - precision_15: 0.9729 - recall_15: 0.9694 - val_loss: 1.2196 - val_categorical_accuracy: 0.5556 - val_precision_15: 0.6026 - val_recall_15: 0.5339\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1436 - categorical_accuracy: 0.9688 - precision_15: 0.9704 - recall_15: 0.9669 - val_loss: 1.4907 - val_categorical_accuracy: 0.5139 - val_precision_15: 0.5175 - val_recall_15: 0.4948\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1368 - categorical_accuracy: 0.9710 - precision_15: 0.9728 - recall_15: 0.9699 - val_loss: 1.2119 - val_categorical_accuracy: 0.5933 - val_precision_15: 0.6348 - val_recall_15: 0.5825\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.1267 - categorical_accuracy: 0.9733 - precision_15: 0.9745 - recall_15: 0.9717 - val_loss: 1.2425 - val_categorical_accuracy: 0.5686 - val_precision_15: 0.6529 - val_recall_15: 0.5503\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1133 - categorical_accuracy: 0.9759 - precision_15: 0.9771 - recall_15: 0.9749 - val_loss: 1.0855 - val_categorical_accuracy: 0.5833 - val_precision_15: 0.6159 - val_recall_15: 0.5686\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1121 - categorical_accuracy: 0.9738 - precision_15: 0.9749 - recall_15: 0.9726 - val_loss: 1.1553 - val_categorical_accuracy: 0.5885 - val_precision_15: 0.6146 - val_recall_15: 0.5681\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1034 - categorical_accuracy: 0.9749 - precision_15: 0.9756 - recall_15: 0.9737 - val_loss: 1.8647 - val_categorical_accuracy: 0.5720 - val_precision_15: 0.5820 - val_recall_15: 0.5638\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1065 - categorical_accuracy: 0.9733 - precision_15: 0.9742 - recall_15: 0.9723 - val_loss: 1.3187 - val_categorical_accuracy: 0.5694 - val_precision_15: 0.5764 - val_recall_15: 0.5534\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0974 - categorical_accuracy: 0.9754 - precision_15: 0.9761 - recall_15: 0.9746 - val_loss: 1.0995 - val_categorical_accuracy: 0.6272 - val_precision_15: 0.6387 - val_recall_15: 0.6115\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0889 - categorical_accuracy: 0.9787 - precision_15: 0.9791 - recall_15: 0.9785 - val_loss: 1.3879 - val_categorical_accuracy: 0.5378 - val_precision_15: 0.5520 - val_recall_15: 0.5204\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0892 - categorical_accuracy: 0.9756 - precision_15: 0.9763 - recall_15: 0.9750 - val_loss: 1.3055 - val_categorical_accuracy: 0.5816 - val_precision_15: 0.6051 - val_recall_15: 0.5660\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0821 - categorical_accuracy: 0.9778 - precision_15: 0.9783 - recall_15: 0.9775 - val_loss: 1.1714 - val_categorical_accuracy: 0.6536 - val_precision_15: 0.6597 - val_recall_15: 0.6345\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0797 - categorical_accuracy: 0.9775 - precision_15: 0.9778 - recall_15: 0.9769 - val_loss: 1.2313 - val_categorical_accuracy: 0.6341 - val_precision_15: 0.6387 - val_recall_15: 0.6076\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0760 - categorical_accuracy: 0.9778 - precision_15: 0.9782 - recall_15: 0.9771 - val_loss: 1.3423 - val_categorical_accuracy: 0.5955 - val_precision_15: 0.6058 - val_recall_15: 0.5803\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0756 - categorical_accuracy: 0.9769 - precision_15: 0.9774 - recall_15: 0.9761 - val_loss: 1.4507 - val_categorical_accuracy: 0.5556 - val_precision_15: 0.5714 - val_recall_15: 0.5438\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0989 - categorical_accuracy: 0.9700 - precision_15: 0.9710 - recall_15: 0.9692 - val_loss: 2.0177 - val_categorical_accuracy: 0.4718 - val_precision_15: 0.4750 - val_recall_15: 0.4418\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.1125 - categorical_accuracy: 0.9664 - precision_15: 0.9678 - recall_15: 0.9650 - val_loss: 1.2664 - val_categorical_accuracy: 0.5916 - val_precision_15: 0.6498 - val_recall_15: 0.5694\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0841 - categorical_accuracy: 0.9757 - precision_15: 0.9764 - recall_15: 0.9746 - val_loss: 1.3322 - val_categorical_accuracy: 0.5673 - val_precision_15: 0.5781 - val_recall_15: 0.5508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1731 - categorical_accuracy: 0.6536 - precision_15: 0.6597 - recall_15: 0.6345\n",
      "Accuracy: 0.6536458134651184\n",
      "Precision: 0.659747302532196\n",
      "Recall: 0.6345486044883728\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.2531 - categorical_accuracy: 0.7253 - precision_16: 0.8301 - recall_16: 0.5690 - val_loss: 0.7617 - val_categorical_accuracy: 0.8609 - val_precision_16: 0.8865 - val_recall_16: 0.8281\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.6258 - categorical_accuracy: 0.8884 - precision_16: 0.9133 - recall_16: 0.8571 - val_loss: 0.6681 - val_categorical_accuracy: 0.8769 - val_precision_16: 0.8949 - val_recall_16: 0.8586\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4922 - categorical_accuracy: 0.9259 - precision_16: 0.9369 - recall_16: 0.9099 - val_loss: 0.6979 - val_categorical_accuracy: 0.8676 - val_precision_16: 0.8819 - val_recall_16: 0.8501\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4189 - categorical_accuracy: 0.9386 - precision_16: 0.9474 - recall_16: 0.9299 - val_loss: 0.7095 - val_categorical_accuracy: 0.8501 - val_precision_16: 0.8692 - val_recall_16: 0.8382\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3645 - categorical_accuracy: 0.9525 - precision_16: 0.9572 - recall_16: 0.9454 - val_loss: 0.6049 - val_categorical_accuracy: 0.8824 - val_precision_16: 0.8883 - val_recall_16: 0.8728\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3282 - categorical_accuracy: 0.9559 - precision_16: 0.9608 - recall_16: 0.9507 - val_loss: 0.6080 - val_categorical_accuracy: 0.8858 - val_precision_16: 0.8967 - val_recall_16: 0.8780\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2980 - categorical_accuracy: 0.9607 - precision_16: 0.9643 - recall_16: 0.9560 - val_loss: 0.6297 - val_categorical_accuracy: 0.8579 - val_precision_16: 0.8695 - val_recall_16: 0.8504\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2748 - categorical_accuracy: 0.9618 - precision_16: 0.9646 - recall_16: 0.9587 - val_loss: 0.5633 - val_categorical_accuracy: 0.8724 - val_precision_16: 0.8851 - val_recall_16: 0.8679\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2591 - categorical_accuracy: 0.9636 - precision_16: 0.9659 - recall_16: 0.9606 - val_loss: 0.6561 - val_categorical_accuracy: 0.8516 - val_precision_16: 0.8664 - val_recall_16: 0.8423\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2393 - categorical_accuracy: 0.9649 - precision_16: 0.9672 - recall_16: 0.9618 - val_loss: 0.5088 - val_categorical_accuracy: 0.9022 - val_precision_16: 0.9099 - val_recall_16: 0.8984\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2252 - categorical_accuracy: 0.9653 - precision_16: 0.9672 - recall_16: 0.9625 - val_loss: 0.6342 - val_categorical_accuracy: 0.8690 - val_precision_16: 0.8749 - val_recall_16: 0.8635\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2081 - categorical_accuracy: 0.9677 - precision_16: 0.9687 - recall_16: 0.9659 - val_loss: 0.5508 - val_categorical_accuracy: 0.8824 - val_precision_16: 0.8950 - val_recall_16: 0.8787\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1972 - categorical_accuracy: 0.9687 - precision_16: 0.9701 - recall_16: 0.9669 - val_loss: 0.6942 - val_categorical_accuracy: 0.8538 - val_precision_16: 0.8603 - val_recall_16: 0.8497\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1806 - categorical_accuracy: 0.9694 - precision_16: 0.9700 - recall_16: 0.9684 - val_loss: 0.5055 - val_categorical_accuracy: 0.8821 - val_precision_16: 0.8904 - val_recall_16: 0.8769\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1745 - categorical_accuracy: 0.9675 - precision_16: 0.9690 - recall_16: 0.9656 - val_loss: 0.6234 - val_categorical_accuracy: 0.8542 - val_precision_16: 0.8654 - val_recall_16: 0.8512\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1598 - categorical_accuracy: 0.9718 - precision_16: 0.9730 - recall_16: 0.9706 - val_loss: 0.4453 - val_categorical_accuracy: 0.9014 - val_precision_16: 0.9121 - val_recall_16: 0.8951\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1649 - categorical_accuracy: 0.9667 - precision_16: 0.9682 - recall_16: 0.9653 - val_loss: 0.7093 - val_categorical_accuracy: 0.8501 - val_precision_16: 0.8584 - val_recall_16: 0.8478\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1649 - categorical_accuracy: 0.9658 - precision_16: 0.9675 - recall_16: 0.9639 - val_loss: 0.5775 - val_categorical_accuracy: 0.8873 - val_precision_16: 0.8936 - val_recall_16: 0.8810\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1489 - categorical_accuracy: 0.9688 - precision_16: 0.9693 - recall_16: 0.9674 - val_loss: 0.5493 - val_categorical_accuracy: 0.8769 - val_precision_16: 0.8866 - val_recall_16: 0.8694\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1322 - categorical_accuracy: 0.9717 - precision_16: 0.9730 - recall_16: 0.9707 - val_loss: 0.4446 - val_categorical_accuracy: 0.8932 - val_precision_16: 0.9020 - val_recall_16: 0.8865\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1222 - categorical_accuracy: 0.9729 - precision_16: 0.9734 - recall_16: 0.9722 - val_loss: 0.4534 - val_categorical_accuracy: 0.8873 - val_precision_16: 0.8994 - val_recall_16: 0.8810\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1138 - categorical_accuracy: 0.9734 - precision_16: 0.9738 - recall_16: 0.9729 - val_loss: 0.5369 - val_categorical_accuracy: 0.8605 - val_precision_16: 0.8689 - val_recall_16: 0.8553\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1172 - categorical_accuracy: 0.9705 - precision_16: 0.9713 - recall_16: 0.9696 - val_loss: 0.5116 - val_categorical_accuracy: 0.8821 - val_precision_16: 0.8877 - val_recall_16: 0.8791\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1338 - categorical_accuracy: 0.9664 - precision_16: 0.9678 - recall_16: 0.9648 - val_loss: 0.5180 - val_categorical_accuracy: 0.8839 - val_precision_16: 0.8857 - val_recall_16: 0.8824\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1216 - categorical_accuracy: 0.9678 - precision_16: 0.9693 - recall_16: 0.9668 - val_loss: 0.5969 - val_categorical_accuracy: 0.8657 - val_precision_16: 0.8749 - val_recall_16: 0.8638\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5230 - categorical_accuracy: 0.9003 - precision_16: 0.9081 - recall_16: 0.8966\n",
      "Accuracy: 0.9002976417541504\n",
      "Precision: 0.9080632925033569\n",
      "Recall: 0.8965773582458496\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 1.2805 - categorical_accuracy: 0.7202 - precision_17: 0.8279 - recall_17: 0.5566 - val_loss: 0.7359 - val_categorical_accuracy: 0.8572 - val_precision_17: 0.8875 - val_recall_17: 0.8040\n",
      "Epoch 2/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.6569 - categorical_accuracy: 0.8790 - precision_17: 0.9050 - recall_17: 0.8439 - val_loss: 0.5462 - val_categorical_accuracy: 0.9240 - val_precision_17: 0.9430 - val_recall_17: 0.9055\n",
      "Epoch 3/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.5204 - categorical_accuracy: 0.9185 - precision_17: 0.9334 - recall_17: 0.9017 - val_loss: 0.5578 - val_categorical_accuracy: 0.9286 - val_precision_17: 0.9356 - val_recall_17: 0.9190\n",
      "Epoch 4/100\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.4398 - categorical_accuracy: 0.9349 - precision_17: 0.9437 - recall_17: 0.9263 - val_loss: 0.4432 - val_categorical_accuracy: 0.9457 - val_precision_17: 0.9496 - val_recall_17: 0.9432\n",
      "Epoch 5/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.3976 - categorical_accuracy: 0.9418 - precision_17: 0.9486 - recall_17: 0.9338 - val_loss: 0.5341 - val_categorical_accuracy: 0.9229 - val_precision_17: 0.9263 - val_recall_17: 0.9197\n",
      "Epoch 6/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.3521 - categorical_accuracy: 0.9480 - precision_17: 0.9531 - recall_17: 0.9424 - val_loss: 0.5355 - val_categorical_accuracy: 0.9233 - val_precision_17: 0.9303 - val_recall_17: 0.9201\n",
      "Epoch 7/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.3193 - categorical_accuracy: 0.9552 - precision_17: 0.9588 - recall_17: 0.9495 - val_loss: 0.4475 - val_categorical_accuracy: 0.9375 - val_precision_17: 0.9407 - val_recall_17: 0.9347\n",
      "Epoch 8/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2901 - categorical_accuracy: 0.9593 - precision_17: 0.9631 - recall_17: 0.9554 - val_loss: 0.4759 - val_categorical_accuracy: 0.9393 - val_precision_17: 0.9411 - val_recall_17: 0.9357\n",
      "Epoch 9/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2674 - categorical_accuracy: 0.9637 - precision_17: 0.9664 - recall_17: 0.9598 - val_loss: 0.4916 - val_categorical_accuracy: 0.9315 - val_precision_17: 0.9353 - val_recall_17: 0.9286\n",
      "Epoch 10/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2539 - categorical_accuracy: 0.9610 - precision_17: 0.9636 - recall_17: 0.9584 - val_loss: 0.4867 - val_categorical_accuracy: 0.9318 - val_precision_17: 0.9350 - val_recall_17: 0.9297\n",
      "Epoch 11/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2342 - categorical_accuracy: 0.9654 - precision_17: 0.9675 - recall_17: 0.9632 - val_loss: 0.4561 - val_categorical_accuracy: 0.9382 - val_precision_17: 0.9404 - val_recall_17: 0.9364\n",
      "Epoch 12/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2168 - categorical_accuracy: 0.9662 - precision_17: 0.9681 - recall_17: 0.9645 - val_loss: 0.4370 - val_categorical_accuracy: 0.9382 - val_precision_17: 0.9391 - val_recall_17: 0.9361\n",
      "Epoch 13/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.2085 - categorical_accuracy: 0.9653 - precision_17: 0.9672 - recall_17: 0.9626 - val_loss: 0.4127 - val_categorical_accuracy: 0.9432 - val_precision_17: 0.9458 - val_recall_17: 0.9418\n",
      "Epoch 14/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1991 - categorical_accuracy: 0.9669 - precision_17: 0.9683 - recall_17: 0.9647 - val_loss: 0.3418 - val_categorical_accuracy: 0.9464 - val_precision_17: 0.9493 - val_recall_17: 0.9450\n",
      "Epoch 15/100\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.1915 - categorical_accuracy: 0.9655 - precision_17: 0.9673 - recall_17: 0.9636 - val_loss: 0.3927 - val_categorical_accuracy: 0.9474 - val_precision_17: 0.9490 - val_recall_17: 0.9442\n",
      "Epoch 16/100\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.1780 - categorical_accuracy: 0.9665 - precision_17: 0.9674 - recall_17: 0.9644 - val_loss: 0.3275 - val_categorical_accuracy: 0.9510 - val_precision_17: 0.9526 - val_recall_17: 0.9496\n",
      "Epoch 17/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1615 - categorical_accuracy: 0.9699 - precision_17: 0.9710 - recall_17: 0.9689 - val_loss: 0.4215 - val_categorical_accuracy: 0.9371 - val_precision_17: 0.9386 - val_recall_17: 0.9339\n",
      "Epoch 18/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1525 - categorical_accuracy: 0.9701 - precision_17: 0.9713 - recall_17: 0.9686 - val_loss: 0.3586 - val_categorical_accuracy: 0.9435 - val_precision_17: 0.9438 - val_recall_17: 0.9421\n",
      "Epoch 19/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1386 - categorical_accuracy: 0.9725 - precision_17: 0.9731 - recall_17: 0.9717 - val_loss: 0.4884 - val_categorical_accuracy: 0.9226 - val_precision_17: 0.9244 - val_recall_17: 0.9212\n",
      "Epoch 20/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1341 - categorical_accuracy: 0.9706 - precision_17: 0.9716 - recall_17: 0.9699 - val_loss: 0.4903 - val_categorical_accuracy: 0.9300 - val_precision_17: 0.9315 - val_recall_17: 0.9276\n",
      "Epoch 21/100\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.1507 - categorical_accuracy: 0.9639 - precision_17: 0.9657 - recall_17: 0.9623 - val_loss: 0.3944 - val_categorical_accuracy: 0.9428 - val_precision_17: 0.9458 - val_recall_17: 0.9414\n",
      "Epoch 22/100\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.1443 - categorical_accuracy: 0.9662 - precision_17: 0.9681 - recall_17: 0.9647 - val_loss: 0.4152 - val_categorical_accuracy: 0.9379 - val_precision_17: 0.9401 - val_recall_17: 0.9357\n",
      "Epoch 23/100\n",
      "156/156 [==============================] - 1s 7ms/step - loss: 0.1383 - categorical_accuracy: 0.9646 - precision_17: 0.9662 - recall_17: 0.9632 - val_loss: 0.3955 - val_categorical_accuracy: 0.9354 - val_precision_17: 0.9388 - val_recall_17: 0.9315\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3220 - categorical_accuracy: 0.9528 - precision_17: 0.9544 - recall_17: 0.9513\n",
      "Accuracy: 0.9527698755264282\n",
      "Precision: 0.9543997049331665\n",
      "Recall: 0.9513494372367859\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 1.1542 - categorical_accuracy: 0.7350 - precision_18: 0.8344 - recall_18: 0.6064 - val_loss: 0.7014 - val_categorical_accuracy: 0.9040 - val_precision_18: 0.9255 - val_recall_18: 0.8562\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.6147 - categorical_accuracy: 0.8929 - precision_18: 0.9168 - recall_18: 0.8594 - val_loss: 0.6912 - val_categorical_accuracy: 0.8709 - val_precision_18: 0.8891 - val_recall_18: 0.8511\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.4890 - categorical_accuracy: 0.9252 - precision_18: 0.9381 - recall_18: 0.9101 - val_loss: 0.6714 - val_categorical_accuracy: 0.8185 - val_precision_18: 0.8397 - val_recall_18: 0.7826\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.4128 - categorical_accuracy: 0.9403 - precision_18: 0.9491 - recall_18: 0.9299 - val_loss: 0.6527 - val_categorical_accuracy: 0.7845 - val_precision_18: 0.7957 - val_recall_18: 0.7716\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.3572 - categorical_accuracy: 0.9516 - precision_18: 0.9566 - recall_18: 0.9453 - val_loss: 0.4716 - val_categorical_accuracy: 0.8851 - val_precision_18: 0.9031 - val_recall_18: 0.8699\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.3260 - categorical_accuracy: 0.9538 - precision_18: 0.9585 - recall_18: 0.9483 - val_loss: 0.5717 - val_categorical_accuracy: 0.8424 - val_precision_18: 0.8496 - val_recall_18: 0.8309\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.2900 - categorical_accuracy: 0.9605 - precision_18: 0.9638 - recall_18: 0.9567 - val_loss: 0.5067 - val_categorical_accuracy: 0.8442 - val_precision_18: 0.8569 - val_recall_18: 0.8309\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.2641 - categorical_accuracy: 0.9629 - precision_18: 0.9655 - recall_18: 0.9604 - val_loss: 0.4908 - val_categorical_accuracy: 0.8488 - val_precision_18: 0.8520 - val_recall_18: 0.8438\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.2500 - categorical_accuracy: 0.9618 - precision_18: 0.9648 - recall_18: 0.9589 - val_loss: 0.3823 - val_categorical_accuracy: 0.8874 - val_precision_18: 0.8943 - val_recall_18: 0.8828\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.2342 - categorical_accuracy: 0.9622 - precision_18: 0.9653 - recall_18: 0.9592 - val_loss: 0.5018 - val_categorical_accuracy: 0.8327 - val_precision_18: 0.8390 - val_recall_18: 0.8263\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.2151 - categorical_accuracy: 0.9667 - precision_18: 0.9689 - recall_18: 0.9646 - val_loss: 0.3139 - val_categorical_accuracy: 0.9504 - val_precision_18: 0.9576 - val_recall_18: 0.9444\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1909 - categorical_accuracy: 0.9714 - precision_18: 0.9730 - recall_18: 0.9695 - val_loss: 0.3513 - val_categorical_accuracy: 0.9131 - val_precision_18: 0.9174 - val_recall_18: 0.9081\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1807 - categorical_accuracy: 0.9693 - precision_18: 0.9705 - recall_18: 0.9682 - val_loss: 0.4229 - val_categorical_accuracy: 0.8479 - val_precision_18: 0.8526 - val_recall_18: 0.8424\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1682 - categorical_accuracy: 0.9719 - precision_18: 0.9729 - recall_18: 0.9706 - val_loss: 0.2649 - val_categorical_accuracy: 0.9517 - val_precision_18: 0.9564 - val_recall_18: 0.9467\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1649 - categorical_accuracy: 0.9703 - precision_18: 0.9714 - recall_18: 0.9686 - val_loss: 0.2901 - val_categorical_accuracy: 0.9403 - val_precision_18: 0.9461 - val_recall_18: 0.9357\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1528 - categorical_accuracy: 0.9715 - precision_18: 0.9725 - recall_18: 0.9697 - val_loss: 0.3553 - val_categorical_accuracy: 0.9136 - val_precision_18: 0.9227 - val_recall_18: 0.9053\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1450 - categorical_accuracy: 0.9716 - precision_18: 0.9728 - recall_18: 0.9702 - val_loss: 0.2693 - val_categorical_accuracy: 0.9426 - val_precision_18: 0.9487 - val_recall_18: 0.9347\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1668 - categorical_accuracy: 0.9628 - precision_18: 0.9649 - recall_18: 0.9603 - val_loss: 0.4684 - val_categorical_accuracy: 0.8782 - val_precision_18: 0.8822 - val_recall_18: 0.8745\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1563 - categorical_accuracy: 0.9646 - precision_18: 0.9663 - recall_18: 0.9625 - val_loss: 0.2898 - val_categorical_accuracy: 0.9200 - val_precision_18: 0.9214 - val_recall_18: 0.9164\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1315 - categorical_accuracy: 0.9715 - precision_18: 0.9727 - recall_18: 0.9704 - val_loss: 0.3855 - val_categorical_accuracy: 0.9081 - val_precision_18: 0.9160 - val_recall_18: 0.8975\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1191 - categorical_accuracy: 0.9725 - precision_18: 0.9732 - recall_18: 0.9718 - val_loss: 0.2949 - val_categorical_accuracy: 0.9085 - val_precision_18: 0.9166 - val_recall_18: 0.9035\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1105 - categorical_accuracy: 0.9740 - precision_18: 0.9747 - recall_18: 0.9733 - val_loss: 0.2683 - val_categorical_accuracy: 0.9136 - val_precision_18: 0.9178 - val_recall_18: 0.9081\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1045 - categorical_accuracy: 0.9740 - precision_18: 0.9744 - recall_18: 0.9732 - val_loss: 0.3399 - val_categorical_accuracy: 0.9205 - val_precision_18: 0.9231 - val_recall_18: 0.9164\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1274 - categorical_accuracy: 0.9654 - precision_18: 0.9673 - recall_18: 0.9642 - val_loss: 0.4073 - val_categorical_accuracy: 0.8883 - val_precision_18: 0.8950 - val_recall_18: 0.8814\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1210 - categorical_accuracy: 0.9687 - precision_18: 0.9698 - recall_18: 0.9675 - val_loss: 0.3923 - val_categorical_accuracy: 0.8525 - val_precision_18: 0.8559 - val_recall_18: 0.8488\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 7ms/step - loss: 0.1086 - categorical_accuracy: 0.9725 - precision_18: 0.9733 - recall_18: 0.9715 - val_loss: 0.4026 - val_categorical_accuracy: 0.8460 - val_precision_18: 0.8512 - val_recall_18: 0.8438\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2645 - categorical_accuracy: 0.9517 - precision_18: 0.9564 - recall_18: 0.9467\n",
      "Accuracy: 0.9517463445663452\n",
      "Precision: 0.9563602805137634\n",
      "Recall: 0.9466911554336548\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 1.1362 - categorical_accuracy: 0.7648 - precision_19: 0.8505 - recall_19: 0.6364 - val_loss: 1.1077 - val_categorical_accuracy: 0.7309 - val_precision_19: 0.8068 - val_recall_19: 0.6867\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5900 - categorical_accuracy: 0.9095 - precision_19: 0.9288 - recall_19: 0.8841 - val_loss: 1.0002 - val_categorical_accuracy: 0.7641 - val_precision_19: 0.7863 - val_recall_19: 0.7402\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4806 - categorical_accuracy: 0.9307 - precision_19: 0.9429 - recall_19: 0.9178 - val_loss: 1.1427 - val_categorical_accuracy: 0.7145 - val_precision_19: 0.7434 - val_recall_19: 0.7004\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.4097 - categorical_accuracy: 0.9426 - precision_19: 0.9494 - recall_19: 0.9346 - val_loss: 0.9295 - val_categorical_accuracy: 0.7898 - val_precision_19: 0.8036 - val_recall_19: 0.7754\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.3603 - categorical_accuracy: 0.9531 - precision_19: 0.9583 - recall_19: 0.9462 - val_loss: 0.8606 - val_categorical_accuracy: 0.7937 - val_precision_19: 0.8069 - val_recall_19: 0.7820\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3234 - categorical_accuracy: 0.9561 - precision_19: 0.9604 - recall_19: 0.9515 - val_loss: 0.9419 - val_categorical_accuracy: 0.7742 - val_precision_19: 0.7920 - val_recall_19: 0.7586\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.2977 - categorical_accuracy: 0.9597 - precision_19: 0.9625 - recall_19: 0.9570 - val_loss: 0.9231 - val_categorical_accuracy: 0.7785 - val_precision_19: 0.7918 - val_recall_19: 0.7664\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2716 - categorical_accuracy: 0.9635 - precision_19: 0.9656 - recall_19: 0.9603 - val_loss: 0.9974 - val_categorical_accuracy: 0.8043 - val_precision_19: 0.8213 - val_recall_19: 0.7969\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2465 - categorical_accuracy: 0.9669 - precision_19: 0.9692 - recall_19: 0.9638 - val_loss: 0.8060 - val_categorical_accuracy: 0.8090 - val_precision_19: 0.8232 - val_recall_19: 0.7930\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2256 - categorical_accuracy: 0.9688 - precision_19: 0.9697 - recall_19: 0.9666 - val_loss: 0.9513 - val_categorical_accuracy: 0.7578 - val_precision_19: 0.7906 - val_recall_19: 0.7449\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2150 - categorical_accuracy: 0.9673 - precision_19: 0.9696 - recall_19: 0.9650 - val_loss: 0.9436 - val_categorical_accuracy: 0.7770 - val_precision_19: 0.7961 - val_recall_19: 0.7609\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1986 - categorical_accuracy: 0.9697 - precision_19: 0.9711 - recall_19: 0.9675 - val_loss: 0.8096 - val_categorical_accuracy: 0.8156 - val_precision_19: 0.8313 - val_recall_19: 0.8047\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1880 - categorical_accuracy: 0.9691 - precision_19: 0.9704 - recall_19: 0.9680 - val_loss: 0.9034 - val_categorical_accuracy: 0.7902 - val_precision_19: 0.8068 - val_recall_19: 0.7734\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1730 - categorical_accuracy: 0.9703 - precision_19: 0.9716 - recall_19: 0.9690 - val_loss: 0.8875 - val_categorical_accuracy: 0.7891 - val_precision_19: 0.7998 - val_recall_19: 0.7805\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1683 - categorical_accuracy: 0.9695 - precision_19: 0.9712 - recall_19: 0.9681 - val_loss: 0.7187 - val_categorical_accuracy: 0.8203 - val_precision_19: 0.8325 - val_recall_19: 0.8098\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1661 - categorical_accuracy: 0.9673 - precision_19: 0.9688 - recall_19: 0.9657 - val_loss: 0.8354 - val_categorical_accuracy: 0.7922 - val_precision_19: 0.8035 - val_recall_19: 0.7781\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1623 - categorical_accuracy: 0.9672 - precision_19: 0.9684 - recall_19: 0.9660 - val_loss: 0.8041 - val_categorical_accuracy: 0.8113 - val_precision_19: 0.8226 - val_recall_19: 0.8004\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1446 - categorical_accuracy: 0.9696 - precision_19: 0.9705 - recall_19: 0.9686 - val_loss: 0.9113 - val_categorical_accuracy: 0.7906 - val_precision_19: 0.8021 - val_recall_19: 0.7820\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.1317 - categorical_accuracy: 0.9716 - precision_19: 0.9725 - recall_19: 0.9706 - val_loss: 0.8814 - val_categorical_accuracy: 0.7867 - val_precision_19: 0.7989 - val_recall_19: 0.7773\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1216 - categorical_accuracy: 0.9727 - precision_19: 0.9732 - recall_19: 0.9719 - val_loss: 0.7899 - val_categorical_accuracy: 0.8035 - val_precision_19: 0.8165 - val_recall_19: 0.7941\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1156 - categorical_accuracy: 0.9726 - precision_19: 0.9733 - recall_19: 0.9718 - val_loss: 0.9041 - val_categorical_accuracy: 0.8059 - val_precision_19: 0.8225 - val_recall_19: 0.7945\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.1140 - categorical_accuracy: 0.9729 - precision_19: 0.9740 - recall_19: 0.9717 - val_loss: 0.8375 - val_categorical_accuracy: 0.8031 - val_precision_19: 0.8148 - val_recall_19: 0.7941\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1050 - categorical_accuracy: 0.9744 - precision_19: 0.9747 - recall_19: 0.9736 - val_loss: 0.8693 - val_categorical_accuracy: 0.7727 - val_precision_19: 0.7831 - val_recall_19: 0.7586\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.0984 - categorical_accuracy: 0.9743 - precision_19: 0.9747 - recall_19: 0.9738 - val_loss: 0.7609 - val_categorical_accuracy: 0.8156 - val_precision_19: 0.8306 - val_recall_19: 0.8082\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1458 - categorical_accuracy: 0.9587 - precision_19: 0.9613 - recall_19: 0.9558 - val_loss: 0.9737 - val_categorical_accuracy: 0.7812 - val_precision_19: 0.7872 - val_recall_19: 0.7746\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1232 - categorical_accuracy: 0.9657 - precision_19: 0.9667 - recall_19: 0.9645 - val_loss: 0.8636 - val_categorical_accuracy: 0.8020 - val_precision_19: 0.8162 - val_recall_19: 0.7926\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1031 - categorical_accuracy: 0.9726 - precision_19: 0.9734 - recall_19: 0.9717 - val_loss: 0.8292 - val_categorical_accuracy: 0.7957 - val_precision_19: 0.8097 - val_recall_19: 0.7859\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.7187 - categorical_accuracy: 0.8203 - precision_19: 0.8325 - recall_19: 0.8098\n",
      "Accuracy: 0.8203125\n",
      "Precision: 0.83253014087677\n",
      "Recall: 0.809765636920929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "user_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']\n",
    "batch_size = 128\n",
    "checkpoint_filepath = './models/checkpoint'\n",
    "\n",
    "models_accuracy = []\n",
    "models_precision = []\n",
    "models_recall = []\n",
    "\n",
    "for user_to_exclude in user_list:\n",
    "\n",
    "    train_dataset_df = dataset_df.loc[(dataset_df['user'] != user_to_exclude)] \n",
    "    train_reference_df = pd.get_dummies(train_dataset_df, columns=['gt'])\n",
    "\n",
    "    test_dataset_df = dataset_df.loc[(dataset_df['user'] == user_to_exclude)] \n",
    "    test_reference_df = pd.get_dummies(test_dataset_df, columns=['gt'])\n",
    "\n",
    "    training_dataset = create_dataset(train_reference_df, batch_size=batch_size, shuffle=True, cache_file=None)\n",
    "    val_dataset = create_dataset(test_reference_df, batch_size=batch_size, shuffle=True, cache_file=None)\n",
    "\n",
    "    train_steps = int(np.ceil(len(train_reference_df)/batch_size))\n",
    "    val_steps = int(np.ceil(len(test_reference_df)/batch_size))\n",
    "\n",
    "    model = build_model((6,125))\n",
    "\n",
    "    adam_optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    loss_funct = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    model.compile(optimizer = adam_optimizer, loss = loss_funct, metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
    "    )\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_categorical_accuracy', mode='max', save_best_only=True)\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    model.fit(training_dataset, epochs = 100, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps,  callbacks = [early_stopping_callback, model_checkpoint_callback])\n",
    "\n",
    "    # L0AD BEST MODEL\n",
    "    # The model weights (that are considered the best) are loaded into the model.\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    metrics = model.evaluate(val_dataset, batch_size=batch_size, steps=val_steps)\n",
    "\n",
    "    loss, accuracy, precision, recall = metrics\n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Recall: ' + str(recall))\n",
    "\n",
    "    models_accuracy.append(accuracy)\n",
    "    models_precision.append(precision)\n",
    "    models_recall.append(recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'models_accuracy' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e22375e088c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy:\\tMean={np.mean(models_accuracy)}\\tstd={np.std(models_accuracy)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Accuracy:\\tMean={np.mean(models_accuracy)}\\tstd={np.std(models_accuracy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}